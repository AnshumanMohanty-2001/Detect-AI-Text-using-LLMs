{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y6R9Puc8053"
   },
   "source": [
    "### Import the necessary libraries\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import string\n",
    "import unicodedata\n",
    "import contractions\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import missingno as msno\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from unidecode import unidecode\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from torch.nn import functional as F\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import EarlyStoppingCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaZktKlS806G"
   },
   "source": [
    "### Load the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Personal Projects/Detect ai text using LLMs/Dataset/Training_Essay_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIa9sZUl806L"
   },
   "source": [
    "### Analyzing the missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FAJM2XP806Q"
   },
   "source": [
    "### Dataset Characterstics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK8OZ577806S"
   },
   "source": [
    "Dataset size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IulBLnM806Z"
   },
   "source": [
    "Checking for Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duplicate Rows: ', len(df[df.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydqgjYVT806g"
   },
   "source": [
    "Check for data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x88nQztM806i"
   },
   "source": [
    "Summary of Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOkoiF2_806n"
   },
   "source": [
    "Class Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['generated'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pgtH38x806s"
   },
   "source": [
    "#### Initial Analysis of dataset\n",
    "\n",
    "<ul>\n",
    "    <li>Dataset initially had 29145 rows.</li>\n",
    "    <li>There are only two columns in the dataset: text column has the essay text and generated column has the label (0 - Human Written Essay , 1 - AI Generated Essay).</li>\n",
    "    <li>The dataset had no missing values.</li>\n",
    "    <li>1805 rows with duplicate values were dropped.</li>\n",
    "    <li>Almost 60% of the rows are human generated and 40% rows are AI generated.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO2brUZ3806t"
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['text'].apply(lambda text: len(re.split(r'\\s+|[' + re.escape(string.punctuation) + r']+', text)) - 1)\n",
    "df['sentence_count'] = df['text'].apply(lambda text: len(nltk.sent_tokenize(text)))\n",
    "df['essay_length'] = df['text'].apply(lambda text: len(text))\n",
    "df['punctuation_count'] = df['text'].apply(lambda text: sum(1 for char in text if char in string.punctuation))\n",
    "df['unique words ratio'] = df['text'].apply(lambda text: len(set(text.split()))/len(text.split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(df, column, label_name):\n",
    "    \"\"\"\n",
    "    Plots a histogram of sentence count color-coded by the 'generated' class.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with 'sentence_count' and 'generated' columns.\n",
    "    \"\"\"\n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Create histogram\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data=df, x=column, hue='generated', bins='auto', kde=True,\n",
    "                 palette={0: 'blue', 1: 'red'}, alpha=0.6)\n",
    "\n",
    "    # Labels & Title\n",
    "    plt.xlabel(f\"{label_name}\", fontsize=12)\n",
    "    plt.ylabel(\"# of essays\", fontsize=12)\n",
    "    plt.title(f\"Distribution of {label_name} by Class\", fontsize=14)\n",
    "    plt.legend(labels=[\"Human (0)\", \"AI (1)\"])\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'word_count', 'Word Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'sentence_count', 'Sentence Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'essay_length', 'Length of Essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'punctuation_count', 'Punctuation Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'unique words ratio', 'Unique Words Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \" \".join(df['text'])\n",
    "words = re.findall(r'\\b\\w+\\b', all_text.lower())\n",
    "word_counts = Counter(words)\n",
    "\n",
    "top_10_words = word_counts.most_common(10)\n",
    "\n",
    "words, counts = zip(*top_10_words)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=list(words), y=list(counts), palette='viridis')\n",
    "\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Top 10 Most Used Words in Text Data\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0l54dUfu8066"
   },
   "source": [
    "Most of the words are Stopwords. So, now I would be preprocessing to remove the stopwords and observe the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD4W_Jev8067"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = unicodedata.normalize(\"NFKC\", text)  # Normalize Unicode\n",
    "    text = unidecode(text)  # Convert accented characters\n",
    "    text = contractions.fix(text)  # Expand contractions\n",
    "    text = text.lower().strip()  # Lowercasing & remove leading/trailing spaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces into one\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Stopword removal\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'generated']]\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOj8El4Y806-"
   },
   "source": [
    "Now i will check for some prior visualizations to analyze the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['word_count'] = train_df['text'].apply(lambda text: len(re.split(r'\\s+|[' + re.escape(string.punctuation) + r']+', text)) - 1)\n",
    "train_df['essay_length'] = train_df['text'].apply(lambda text: len(text))\n",
    "train_df['unique words ratio'] = train_df['text'].apply(lambda text: len(set(text.split()))/len(text.split()))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(train_df, 'word_count', 'Word Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(train_df, 'essay_length', 'Length of Essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(train_df, 'unique words ratio', 'Unique Words Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "text_data = \" \".join(train_df['text'].dropna())\n",
    "generate_wordcloud(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49AKLHB8pz4S"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['text', 'generated']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOU_2l0Up785"
   },
   "source": [
    "#### Analysis of Feature Engineering\n",
    "\n",
    "Based on the above, plots, there isn't a significant distinction of both classes. So, I will use only the given features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEqMMIFA808O"
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit on train data and transform both train and validation data\n",
    "X_train = vectorizer.fit_transform(train_df['text']).toarray()\n",
    "X_val = vectorizer.transform(val_df['text']).toarray()\n",
    "\n",
    "# Step 2: Extract target labels\n",
    "y_train = train_df['generated']  # Assuming 'generated' is the target column\n",
    "y_val = val_df['generated']  # Target for validation data\n",
    "\n",
    "# Step 3: Convert data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Step 4: Define XGBoost parameters with GPU acceleration\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification (0 or 1)\n",
    "    'eval_metric': 'logloss',  # Log loss for binary classification\n",
    "    'tree_method': 'gpu_hist',  # Use GPU for training\n",
    "    'predictor': 'gpu_predictor',  # Use GPU for prediction\n",
    "    'verbosity': 1  # Show training progress\n",
    "}\n",
    "\n",
    "# Step 5: Train the model\n",
    "model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dval, 'Validation')], early_stopping_rounds=10)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = model.predict(dval)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred]  # Convert probabilities to 0 or 1\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Visualize Confusion Matrix using Seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Human Generated', 'AI Generated'], yticklabels=['Human Generated', 'AI Generated'])\n",
    "plt.title(\"Confusion Matrix (XgBoost)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Logistic Regression):\")\n",
    "print(classification_report(y_val, y_pred_lr))\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_lr)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_lr = confusion_matrix(y_val, y_pred_lr)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_lr, annot=True, fmt='d', cmap='Blues', xticklabels=['Human Generated', 'AI Generated'], yticklabels=['Human Generated', 'AI Generated'])\n",
    "plt.title(\"Confusion Matrix (Logistic Regression)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb = nb_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Naive Bayes):\")\n",
    "print(classification_report(y_val, y_pred_nb))\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_nb)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_nb = confusion_matrix(y_val, y_pred_nb)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_nb, annot=True, fmt='d', cmap='Blues', xticklabels=['Human Generated', 'AI Generated'], yticklabels=['Human Generated', 'AI Generated'])\n",
    "plt.title(\"Confusion Matrix (Naive Bayes)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Gradient Boosting):\")\n",
    "print(classification_report(y_val, y_pred_gb))\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_gb)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_gb = confusion_matrix(y_val, y_pred_gb)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_gb, annot=True, fmt='d', cmap='Blues', xticklabels=['Human Generated', 'AI Generated'], yticklabels=['Human Generated', 'AI Generated'])\n",
    "plt.title(\"Confusion Matrix (Gradient Boosting)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (KNN):\")\n",
    "print(classification_report(y_val, y_pred_knn))\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_knn)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_knn = confusion_matrix(y_val, y_pred_knn)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Blues', xticklabels=['Human Generated', 'AI Generated'], yticklabels=['Human Generated', 'AI Generated'])\n",
    "plt.title(\"Confusion Matrix (KNN)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "# Define model parameters\n",
    "params = {\n",
    "    'objective': 'binary',       # Binary classification\n",
    "    'metric': 'binary_error',    # Performance metric\n",
    "    'boosting_type': 'gbdt',     # Gradient Boosting Decision Tree\n",
    "    'num_leaves': 31,            # Number of leaves in one tree\n",
    "    'learning_rate': 0.05,       # Step size shrinkage\n",
    "    'feature_fraction': 0.9,     # Use 90% of features\n",
    "    'bagging_fraction': 0.8,     # Use 80% of data (bagging)\n",
    "    'bagging_freq': 5,           # Perform bagging every 5 iterations\n",
    "    'verbose': -1,\n",
    "    'device': 'gpu'              # Use GPU if available\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, val_data], num_boost_round=200)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = (lgb_model.predict(X_val) > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (LightGBM):\")\n",
    "print(classification_report(y_val, y_pred_lgb))\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_lgb)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_lgb = confusion_matrix(y_val, y_pred_lgb)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_lgb, annot=True, fmt='d', cmap='Blues', xticklabels=['Human Generated', 'AI Generated'], yticklabels=['Human Generated', 'AI Generated'])\n",
    "plt.title(\"Confusion Matrix (LightGBM)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "max_words = 10000  # Vocabulary size\n",
    "max_length = 300   # Sequence length\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
    "X_val_seq = tokenizer.texts_to_sequences(val_df['text'])\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_val_padded = pad_sequences(X_val_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(train_df['generated'])\n",
    "y_val_encoded = encoder.transform(val_df['generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build the Enhanced CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=256, input_length=max_length),  # Larger embedding layer\n",
    "\n",
    "    Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(filters=64, kernel_size=7, activation='relu', padding='same'),\n",
    "    GlobalMaxPooling1D(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model for 100 epochs\n",
    "cnn_model.fit(X_train_padded, y_train_encoded,\n",
    "              epochs=100,\n",
    "              validation_data=(X_val_padded, y_val_encoded),\n",
    "              batch_size=64,\n",
    "              callbacks=[early_stopping])  # Early stopping added\n",
    "\n",
    "# Predict\n",
    "y_pred_cnn = (cnn_model.predict(X_val_padded) > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report (CNN):\")\n",
    "print(classification_report(y_val_encoded, y_pred_cnn))\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_cnn)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_cnn = confusion_matrix(y_val_encoded, y_pred_cnn)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_cnn, annot=True, fmt='d', cmap='Blues', xticklabels=['Human', 'AI'], yticklabels=['Human', 'AI'])\n",
    "plt.title(\"Confusion Matrix (CNN)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN-LSTM Model\n",
    "cnn_lstm_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=256, input_length=max_length),  # Larger embedding layer\n",
    "\n",
    "    Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(filters=64, kernel_size=7, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),  # LSTM added\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model for 100 epochs\n",
    "cnn_lstm_model.fit(X_train_padded, y_train_encoded,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_padded, y_val_encoded),\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stopping])  # Early stopping added\n",
    "\n",
    "# Predict\n",
    "y_pred_cnn_lstm = (cnn_lstm_model.predict(X_val_padded) > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report (CNN-LSTM):\")\n",
    "print(classification_report(y_val_encoded, y_pred_cnn_lstm))\n",
    "\n",
    "accuracy = accuracy_score(y_val_encoded, y_pred_cnn_lstm)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_cnn_lstm = confusion_matrix(y_val_encoded, y_pred_cnn_lstm)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_cnn_lstm, annot=True, fmt='d', cmap='Blues', xticklabels=['Human', 'AI'], yticklabels=['Human', 'AI'])\n",
    "plt.title(\"Confusion Matrix (CNN-LSTM)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Splitting dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df[\"generated\"].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = [tokenize_function(text) for text in texts]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = {key: val.squeeze(0) for key, val in self.encodings[idx].items()}\n",
    "        encoding[\"labels\"] = self.labels[idx]\n",
    "        return encoding\n",
    "\n",
    "# Creating PyTorch dataset\n",
    "train_dataset = CustomDataset(train_texts, train_labels)\n",
    "val_dataset = CustomDataset(val_texts, val_labels)\n",
    "\n",
    "# Creating DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Set the device (GPU or CPU)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",  # Save the model at the end of each epoch\n",
    "    num_train_epochs=15,  # Train for 15 epochs\n",
    "    per_device_train_batch_size=64,  # Training batch size\n",
    "    per_device_eval_batch_size=64,  # Evaluation batch size\n",
    "    logging_dir=\"./logs\",  # Log directory\n",
    "    logging_steps=10,  # Log every 10 steps\n",
    "    save_total_limit=2,  # Keep only the last two saved models\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Use validation loss as the metric\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    "    weight_decay=0.01,  # Apply weight decay\n",
    "    push_to_hub=False,  # Prevent unnecessary hub uploads\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)\n",
    "\n",
    "# Function to compute accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    predictions = logits.argmax(axis=1)  # Convert logits to predicted class\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  # Fix function format\n",
    "    callbacks=[early_stopping_callback],  # Add early stopping callback\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"Validation Loss: {eval_results['eval_loss']}\")\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/Personal Projects/Detect ai text using LLMs/saved_model\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/Personal Projects/Detect ai text using LLMs/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 Validation Accuracy per Epoch:\")\n",
    "epochs, val_acc, val_loss = [], [], []\n",
    "for log in trainer.state.log_history:\n",
    "    if \"eval_accuracy\" in log:\n",
    "        epoch = log.get(\"epoch\")\n",
    "        acc = log[\"eval_accuracy\"]\n",
    "        loss = log[\"eval_loss\"]\n",
    "        print(f\"Epoch {int(epoch)}: Accuracy = {acc:.4f}, Loss = {loss:.4f}\")\n",
    "        epochs.append(epoch)\n",
    "        val_acc.append(acc)\n",
    "        val_loss.append(loss)\n",
    "\n",
    "# Plotting validation accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, val_acc, marker='o', label='Validation Accuracy')\n",
    "plt.title(\"Validation Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, val_loss, marker='o', label='Validation Loss', color='orange')\n",
    "plt.title(\"Validation Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on validation set & classification report\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "for batch in val_dataloader:\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, axis=1).cpu().numpy()\n",
    "    labels = batch[\"labels\"].numpy()\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "print(\"\\n📝 Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_bert = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_bert, annot=True, fmt='d', cmap='Blues', xticklabels=['Human', 'AI'], yticklabels=['Human', 'AI'])\n",
    "plt.title(\"Confusion Matrix (Distill BERT)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2aZBy6Vs4ea"
   },
   "source": [
    "#### Conclusion\n",
    "\n",
    "DistilBert outperformed all the other model and achieved an accuracy of 99.82%.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
